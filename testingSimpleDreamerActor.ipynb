{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import TanhTransform\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity=\"relu\")\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def build_network(input_size, hidden_size, num_layers, activation, output_size):\n",
    "    assert num_layers >= 2, \"num_layers must be at least 2\"\n",
    "    activation = getattr(nn, activation)()\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(input_size, hidden_size))\n",
    "    layers.append(activation)\n",
    "\n",
    "    for i in range(num_layers - 2):\n",
    "        layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        layers.append(activation)\n",
    "\n",
    "    layers.append(nn.Linear(hidden_size, output_size))\n",
    "\n",
    "    network = nn.Sequential(*layers)\n",
    "    network.apply(initialize_weights)\n",
    "    return network\n",
    "\n",
    "def create_normal_dist(\n",
    "    x,\n",
    "    std=None,\n",
    "    mean_scale=1,\n",
    "    init_std=0,\n",
    "    min_std=0.1,\n",
    "    activation=None,\n",
    "    event_shape=None,\n",
    "):\n",
    "    if std == None:\n",
    "        mean, std = torch.chunk(x, 2, -1)\n",
    "        mean = mean / mean_scale\n",
    "        if activation:\n",
    "            mean = activation(mean)\n",
    "        mean = mean_scale * mean\n",
    "        std = F.softplus(std + init_std) + min_std\n",
    "    else:\n",
    "        mean = x\n",
    "    dist = torch.distributions.Normal(mean, std)\n",
    "    if event_shape:\n",
    "        dist = torch.distributions.Independent(dist, event_shape)\n",
    "    return dist\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, inputSize, actionSize):\n",
    "        super().__init__()\n",
    "\n",
    "        actionSize *= 2\n",
    "        self.network = sequentialModel1D(inputSize, [256, 256], actionSize)\n",
    "\n",
    "    def forward(self, posterior, deterministic):\n",
    "        x = torch.cat((posterior, deterministic), -1)\n",
    "        x = self.network(x)\n",
    "        dist = create_normal_dist(\n",
    "            x,\n",
    "            mean_scale=5,\n",
    "            init_std=5,\n",
    "            min_std=0.0001,\n",
    "            activation=torch.tanh,\n",
    "        )\n",
    "        entropy = dist.entropy()\n",
    "        dist = torch.distributions.TransformedDistribution(dist, TanhTransform())\n",
    "        action = torch.distributions.Independent(dist, 1).rsample()\n",
    "        return action, dist.log_prob(action).sum(-1), entropy.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Shape: torch.Size([10, 5])\n",
      "Sample Action: tensor([-0.2095,  0.8946, -0.7467,  0.3338,  0.3915],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "logprobs: tensor([ 1.1874, 15.0395, -1.8972,  5.8088,  1.0603,  5.1731, -1.8401, -0.7238,\n",
      "         1.7265,  0.7875], grad_fn=<SumBackward1>) of shape torch.Size([10])\n",
      "entropy: tensor([3.1522, 5.0611, 4.2803, 3.6965, 7.3899, 4.6184, 6.2805, 4.3084, 4.7270,\n",
      "        4.4729], grad_fn=<SumBackward1>) of shape torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "def attrdict_monkeypatch_fix():\n",
    "    import collections\n",
    "    import collections.abc\n",
    "    for type_name in collections.abc.__all__:\n",
    "            setattr(collections, type_name, getattr(collections.abc, type_name))\n",
    "attrdict_monkeypatch_fix()\n",
    "\n",
    "import torch\n",
    "from attrdict import AttrDict\n",
    "from torch.distributions import TanhTransform\n",
    "\n",
    "# Dummy Configurations\n",
    "config = AttrDict({\n",
    "    \"parameters\": AttrDict({\n",
    "        \"dreamer\": AttrDict({\n",
    "            \"agent\": AttrDict({\n",
    "                \"actor\": AttrDict({\n",
    "                    \"hidden_size\": 128,\n",
    "                    \"num_layers\": 3,\n",
    "                    \"activation\": \"ReLU\",\n",
    "                    \"mean_scale\": 5.0,\n",
    "                    \"init_std\": 0.0,\n",
    "                    \"min_std\": 0.1,\n",
    "                })\n",
    "            }),\n",
    "            \"stochastic_size\": 30,\n",
    "            \"deterministic_size\": 200,\n",
    "        })\n",
    "    })\n",
    "})\n",
    "\n",
    "# Actor Initialization\n",
    "action_size = 5  # Number of actions\n",
    "discrete_action_bool = False  # Test for continuous actions\n",
    "actor = Actor(discrete_action_bool, action_size, config)\n",
    "\n",
    "# Inputs to Actor\n",
    "batch_size = 10\n",
    "posterior = torch.randn(batch_size, config.parameters.dreamer.stochastic_size)\n",
    "deterministic = torch.randn(batch_size, config.parameters.dreamer.deterministic_size)\n",
    "\n",
    "# Forward Pass\n",
    "actions, logprobs, entropy = actor(posterior, deterministic)\n",
    "\n",
    "# Display Results\n",
    "print(\"Action Shape:\", actions.shape)\n",
    "print(\"Sample Action:\", actions[0])\n",
    "print(f\"logprobs: {logprobs} of shape {logprobs.shape}\")\n",
    "print(f\"entropy: {entropy} of shape {entropy.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
