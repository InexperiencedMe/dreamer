{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards: [1, 0, 0, 1, 0, 2]\n",
      "Values: [0.5, 0.6, 0.4, 0.7, 0.9, 0.8, 0.0]\n",
      "Lambda-returns: tensor([3.4506, 2.5741, 2.7159, 2.8509, 1.9206, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def lambdaReturns(rewards, values, gamma=0.99, lambda_=0.95):\n",
    "    n = len(rewards)\n",
    "    returns = torch.zeros(n)\n",
    "    bootstrap = values[-1]\n",
    "    for t in reversed(range(n)):\n",
    "        returns[t] = rewards[t] + gamma*((1 - lambda_)*values[t + 1] + lambda_*bootstrap)\n",
    "        bootstrap = returns[t]\n",
    "    return returns\n",
    "\n",
    "rewards = [1, 0, 0, 1, 0, 2]\n",
    "values = [0.5, 0.6, 0.4, 0.7, 0.9, 0.8, 0.0]\n",
    "\n",
    "gamma = 0.99\n",
    "lambda_ = 0.95\n",
    "lmbdaReturns = lambdaReturns(rewards, values, gamma, lambda_)\n",
    "\n",
    "print(\"Rewards:\", rewards)\n",
    "print(\"Values:\", values)\n",
    "print(\"Lambda-returns:\", lmbdaReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda-returns: tensor([2.5676, 1.6352, 1.7176, 1.7894, 0.7920])\n"
     ]
    }
   ],
   "source": [
    "rewards = torch.tensor([1, 0, 0, 1, 0, 2])\n",
    "values = torch.tensor([0.5, 0.6, 0.4, 0.7, 0.9, 0.8])\n",
    "rewards = rewards[:-1]\n",
    "next_values = values[1:]\n",
    "last = next_values[-1]\n",
    "horizonLength = 6\n",
    "gamma = 0.99\n",
    "inputs = rewards + gamma * next_values * (1 - lambda_)\n",
    "\n",
    "outputs = []\n",
    "# single step\n",
    "for index in reversed(range(horizonLength - 1)):\n",
    "    last = inputs[index] + gamma * lambda_ * last\n",
    "    outputs.append(last)\n",
    "returns = torch.stack(list(reversed(outputs)))\n",
    "print(\"Lambda-returns:\", returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards: [1, 0, 0, 1, 0, 2]\n",
      "Values: [0.5, 0.6, 0.4, 0.7, 0.9, 0.8]\n",
      "Lambda-returns: tensor([2.5676, 1.6352, 1.7176, 1.7894, 0.7920])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def lambdaReturns(rewards, values, gamma=0.99, lambda_=0.95):\n",
    "    horizonLength = len(rewards)\n",
    "    bootstrap = values[-1]\n",
    "    returns = torch.zeros(horizonLength - 1)\n",
    "    for t in reversed(range(horizonLength - 1)):\n",
    "        returns[t] = rewards[t] + gamma*((1 - lambda_)*values[t + 1] + lambda_*bootstrap)\n",
    "        bootstrap = returns[t]\n",
    "    return returns\n",
    "\n",
    "rewards = [1, 0, 0, 1, 0, 2]\n",
    "values = [0.5, 0.6, 0.4, 0.7, 0.9, 0.8]\n",
    "\n",
    "gamma = 0.99\n",
    "lambda_ = 0.95\n",
    "lmbdaReturns = lambdaReturns(rewards, values, gamma, lambda_)\n",
    "\n",
    "print(\"Rewards:\", rewards)\n",
    "print(\"Values:\", values)\n",
    "print(\"Lambda-returns:\", lmbdaReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda returns: tensor([1.6676, 1.6884, 1.7741, 0.8394, 0.7920])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def lambdaReturns(rewards, nextValues, lambda_=0.95, gamma=0.99):\n",
    "    td_targets = rewards + gamma * nextValues\n",
    "    returns = torch.zeros_like(rewards)\n",
    "    bootstrap = td_targets[-1]  # Initialize with last TD target\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        returns[t] = (1 - lambda_) * td_targets[t] + lambda_ * bootstrap\n",
    "        bootstrap = rewards[t] + gamma * returns[t]\n",
    "    return returns\n",
    "\n",
    "# Example usage\n",
    "rewards = torch.tensor([1., 0., 0., 1., 0., 2.])\n",
    "values = torch.tensor([0.5, 0.6, 0.4, 0.7, 0.9, 0.8])\n",
    "\n",
    "# Use all but last reward, and all values\n",
    "lambda_returns = lambdaReturns(rewards[:-1], values[1:])\n",
    "print(\"Lambda returns:\", lambda_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns: tensor([2.5545, 1.6265, 1.6978, 1.7842, 0.7970])\n"
     ]
    }
   ],
   "source": [
    "rewards = torch.tensor([1., 0., 0., 1., 0., 2.])\n",
    "values = torch.tensor([0.5, 0.6, 0.4, 0.7, 0.9, 0.8])\n",
    "horizonLength = len(rewards)\n",
    "returns = torch.zeros_like(rewards[:-1])\n",
    "\n",
    "bootstrap = values[-1]\n",
    "for i in reversed(range(len(returns))):\n",
    "    returns[i] = rewards[i] + gamma * ((1 - lambda_)*values[i] + lambda_*bootstrap)\n",
    "    bootstrap = returns[i]\n",
    "\n",
    "print(f\"returns: {returns}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
