{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env CarRacing-v3 with observations tensor([96, 96,  3]) and actions tensor([3])\n",
      "###\n",
      "\n",
      "i    500: worldModelLoss, criticLoss, actorLoss, reward =   1.2315,   0.0157,   3.4734, -3.62\n",
      "Saved html plot to plots/CarRacing-v3_BATCH_TEST_2_500.html\n",
      "Saved video to videos/CarRacing-v3_BATCH_TEST_2_500_reward_0.mp4\n",
      "i   1000: worldModelLoss, criticLoss, actorLoss, reward =   1.1784,   0.0151,   5.3605, -6.27\n",
      "Saved html plot to plots/CarRacing-v3_BATCH_TEST_2_1000.html\n",
      "Saved video to videos/CarRacing-v3_BATCH_TEST_2_1000_reward_-4.mp4\n",
      "i   1500: worldModelLoss, criticLoss, actorLoss, reward =   1.1690,   0.0188,   0.5228, -1.19\n",
      "Saved html plot to plots/CarRacing-v3_BATCH_TEST_2_1500.html\n",
      "Saved video to videos/CarRacing-v3_BATCH_TEST_2_1500_reward_-4.mp4\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils import *\n",
    "from dreamer import *\n",
    "import random\n",
    "torch.set_printoptions(threshold=2000, linewidth=200, sci_mode=False)\n",
    "np.set_printoptions(threshold=2000, linewidth=200)\n",
    "\n",
    "environmentName = \"CarRacing-v3\"\n",
    "renderMode = None\n",
    "numUpdates = 10000\n",
    "episodesBeforeStart = 20\n",
    "playInterval = 10\n",
    "stepCountLimit = 256\n",
    "bufferSize = 20\n",
    "resume = False\n",
    "saveMetrics = True\n",
    "saveCheckpoints = True\n",
    "runName = f\"{environmentName}_BATCH_TEST_2\"\n",
    "checkpointToLoad = f\"checkpoints/{runName}_5500\"\n",
    "metricsFilename = f\"metrics/{runName}\"\n",
    "plotFilename = f\"plots/{runName}\"\n",
    "videoFilename = f\"videos/{runName}\"\n",
    "saveMetricsInterval = 10\n",
    "checkpointInterval = 500\n",
    "numNewEpisodePlay = 1\n",
    "seed = 1\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make(environmentName, render_mode=renderMode)\n",
    "observationShape = torch.tensor(env.observation_space.shape)\n",
    "actionSize = torch.tensor(env.action_space.shape) if hasattr(env.action_space, 'shape') else np.array([env.action_space.n])\n",
    "print(f\"Env {environmentName} with observations {observationShape} and actions {actionSize}\\n###\\n\")\n",
    "dreamer = Dreamer()\n",
    "\n",
    "episodeBuffer = EpisodeBuffer(size=bufferSize)\n",
    "\n",
    "if resume:\n",
    "    dreamer.loadCheckpoint(checkpointToLoad)\n",
    "    start = dreamer.totalUpdates\n",
    "else:\n",
    "    start = 0\n",
    "\n",
    "for i in range(start - episodesBeforeStart, start + numUpdates + 1):\n",
    "    for _ in range(numNewEpisodePlay):\n",
    "        if i % playInterval == 0 or i < start:\n",
    "            observation, info = env.reset(seed=seed + abs(i))\n",
    "            observation = torch.from_numpy(np.transpose(observation, (2, 0, 1))).unsqueeze(0).to(device).float()/255.0\n",
    "            observations, actions, rewards, dones = [observation], [], [], []\n",
    "            stepCount, totalReward, done = 1, 0, False\n",
    "            while not done:\n",
    "                action = dreamer.act(observation, reset=(stepCount == 1)).view(-1)\n",
    "                observation, reward, terminated, truncated, info = env.step(action.cpu().numpy())\n",
    "                observation = torch.from_numpy(np.transpose(observation, (2, 0, 1))).unsqueeze(0).to(device).float()/255.0\n",
    "                stepCount += 1\n",
    "                done = terminated or truncated or stepCount >= stepCountLimit\n",
    "                totalReward += reward\n",
    "                \n",
    "                observations.append(observation)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                # dones.append(done)\n",
    "\n",
    "            episodeBuffer.addEpisode(torch.stack(observations).squeeze(1),\n",
    "                                    torch.stack(actions).to(device),\n",
    "                                    torch.tensor(rewards).to(device))\n",
    "\n",
    "    if i > start:\n",
    "        selectedEpisodeObservations, selectedEpisodeActions, selectedEpisodeRewards = episodeBuffer.sampleEpisodes(dreamer.worldModelBatchSize)\n",
    "        sampledFullStates, worldModelLoss, reconstructionLoss, rewardPredictionLoss, klLoss = dreamer.trainWorldModel(selectedEpisodeObservations, selectedEpisodeActions, selectedEpisodeRewards)\n",
    "        criticLoss, actorLoss, valueEstimate = dreamer.trainActorCritic(sampledFullStates)\n",
    "\n",
    "    if i % saveMetricsInterval == 0 and i > start and saveMetrics:\n",
    "        saveLossesToCSV(metricsFilename, {\n",
    "            \"i\": i,\n",
    "            \"worldModelLoss\": worldModelLoss,\n",
    "            \"reconstructionLoss\": reconstructionLoss,\n",
    "            \"rewardPredictionLoss\": rewardPredictionLoss,\n",
    "            \"klLoss\": klLoss,\n",
    "            \"criticLoss\": criticLoss,\n",
    "            \"actorLoss\": actorLoss,\n",
    "            \"valueEstimate\": valueEstimate,\n",
    "            \"totalReward\": totalReward})\n",
    "        \n",
    "        # print(f\"\\nnewest actions:\\n{episodeBuffer.getNewestEpisode()[1][:5]}\")\n",
    "\n",
    "    if i % checkpointInterval == 0 and i > start and saveCheckpoints:\n",
    "        print(f\"i {i:6}: worldModelLoss, criticLoss, actorLoss, reward = {worldModelLoss:8.4f}, {criticLoss:8.4f}, {actorLoss:8.4f}, {totalReward:.2f}\")\n",
    "        dreamer.totalUpdates = i\n",
    "        dreamer.saveCheckpoint(f\"checkpoints/{runName}_{i}\")\n",
    "        plotMetrics(metricsFilename, show=False, save=True, savePath=f\"{plotFilename}_{i}\") # TODO: plot should replace the unnecessary previous file\n",
    "        saveVideoFromGymEnv(dreamer, environmentName, f\"{videoFilename}_{i}\", frameLimit=stepCountLimit)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mean.0.weight\n",
      "Shape: torch.Size([256, 768])\n",
      "Values: tensor([[    -0.0331,      0.0012,     -0.0354,  ...,      0.0315,      0.0322,     -0.0177],\n",
      "        [     0.0145,     -0.0210,     -0.0288,  ...,      0.0133,     -0.0062,      0.0270],\n",
      "        [     0.0224,     -0.0248,     -0.0294,  ...,      0.0235,     -0.0116,     -0.0091],\n",
      "        ...,\n",
      "        [     0.0067,     -0.0067,      0.0121,  ...,      0.0245,     -0.0059,      0.0135],\n",
      "        [    -0.0284,     -0.0181,     -0.0026,  ...,      0.0047,      0.0190,      0.0314],\n",
      "        [     0.0293,      0.0203,      0.0200,  ...,      0.0203,      0.0153,      0.0000]], device='cuda:0')\n",
      "\n",
      "Name: mean.0.bias\n",
      "Shape: torch.Size([256])\n",
      "Values: tensor([     0.0297,      0.0252,     -0.0018,      0.0204,      0.0206,     -0.0297,     -0.0096,      0.0294,     -0.0308,     -0.0157,     -0.0057,     -0.0061,     -0.0188,     -0.0122,\n",
      "            -0.0313,     -0.0185,      0.0112,      0.0270,      0.0078,     -0.0238,      0.0156,     -0.0004,     -0.0338,     -0.0136,     -0.0218,      0.0275,     -0.0302,      0.0216,\n",
      "            -0.0146,     -0.0118,      0.0004,      0.0229,     -0.0094,      0.0155,     -0.0262,      0.0285,      0.0267,      0.0008,     -0.0160,      0.0083,      0.0014,      0.0302,\n",
      "            -0.0219,     -0.0271,      0.0199,     -0.0137,      0.0258,      0.0105,      0.0072,     -0.0162,      0.0063,      0.0114,      0.0001,      0.0310,      0.0188,      0.0172,\n",
      "            -0.0166,      0.0262,      0.0359,     -0.0186,     -0.0314,      0.0128,     -0.0196,     -0.0137,     -0.0122,     -0.0033,      0.0154,      0.0133,     -0.0088,      0.0032,\n",
      "             0.0041,      0.0070,      0.0315,      0.0177,      0.0296,     -0.0148,      0.0093,      0.0025,     -0.0278,      0.0279,      0.0236,      0.0034,     -0.0166,     -0.0297,\n",
      "             0.0333,      0.0135,     -0.0339,      0.0022,     -0.0212,     -0.0107,     -0.0095,      0.0255,      0.0077,     -0.0105,     -0.0218,     -0.0208,     -0.0157,      0.0169,\n",
      "             0.0189,     -0.0368,      0.0180,     -0.0298,     -0.0074,      0.0084,      0.0063,     -0.0243,     -0.0255,      0.0287,      0.0206,     -0.0062,      0.0365,      0.0322,\n",
      "             0.0169,      0.0206,     -0.0343,      0.0295,      0.0266,      0.0338,      0.0315,     -0.0366,      0.0184,     -0.0055,      0.0238,     -0.0170,      0.0161,      0.0229,\n",
      "            -0.0332,      0.0309,      0.0144,      0.0277,     -0.0315,     -0.0254,      0.0205,     -0.0201,     -0.0319,     -0.0083,      0.0142,     -0.0134,     -0.0070,      0.0101,\n",
      "            -0.0076,     -0.0174,      0.0169,      0.0324,     -0.0304,      0.0204,      0.0232,     -0.0127,     -0.0150,     -0.0324,      0.0224,     -0.0197,      0.0335,     -0.0290,\n",
      "             0.0338,      0.0096,      0.0298,     -0.0170,      0.0047,      0.0158,      0.0135,     -0.0369,      0.0206,      0.0238,     -0.0272,     -0.0038,      0.0065,      0.0225,\n",
      "             0.0184,     -0.0151,     -0.0166,      0.0157,      0.0102,     -0.0332,     -0.0074,     -0.0142,      0.0302,     -0.0326,     -0.0079,     -0.0010,      0.0200,     -0.0192,\n",
      "             0.0300,     -0.0288,     -0.0317,     -0.0324,      0.0285,      0.0246,     -0.0218,     -0.0243,     -0.0138,     -0.0312,      0.0213,     -0.0253,      0.0064,      0.0326,\n",
      "             0.0287,     -0.0375,      0.0245,     -0.0125,      0.0217,     -0.0371,      0.0242,      0.0230,      0.0288,      0.0267,     -0.0169,      0.0035,      0.0126,      0.0060,\n",
      "            -0.0074,      0.0136,     -0.0169,     -0.0331,      0.0231,     -0.0089,      0.0024,      0.0036,     -0.0142,     -0.0101,      0.0081,      0.0338,      0.0026,      0.0132,\n",
      "             0.0099,      0.0191,     -0.0052,      0.0120,     -0.0298,     -0.0101,     -0.0009,      0.0085,     -0.0194,     -0.0211,     -0.0293,     -0.0074,     -0.0374,     -0.0319,\n",
      "             0.0331,     -0.0319,     -0.0105,      0.0015,      0.0259,     -0.0282,      0.0201,     -0.0313,      0.0143,     -0.0235,     -0.0283,     -0.0216,      0.0066,     -0.0102,\n",
      "             0.0035,      0.0027,      0.0220,     -0.0066], device='cuda:0')\n",
      "\n",
      "Name: mean.2.weight\n",
      "Shape: torch.Size([256, 256])\n",
      "Values: tensor([[ 0.0253, -0.0133,  0.0336,  ...,  0.0346, -0.0199,  0.0227],\n",
      "        [ 0.0602,  0.0595, -0.0123,  ...,  0.0033, -0.0144,  0.0168],\n",
      "        [-0.0470, -0.0313, -0.0357,  ...,  0.0371,  0.0035,  0.0100],\n",
      "        ...,\n",
      "        [ 0.0382, -0.0021,  0.0065,  ..., -0.0377, -0.0402,  0.0157],\n",
      "        [-0.0502,  0.0062, -0.0453,  ...,  0.0494, -0.0162,  0.0115],\n",
      "        [ 0.0328, -0.0195, -0.0173,  ...,  0.0440, -0.0335, -0.0057]], device='cuda:0')\n",
      "\n",
      "Name: mean.2.bias\n",
      "Shape: torch.Size([256])\n",
      "Values: tensor([ 0.0609,  0.0182, -0.0271, -0.0335, -0.0051,  0.0596,  0.0330,  0.0488, -0.0559, -0.0460, -0.0521, -0.0082, -0.0547, -0.0536,  0.0515,  0.0184, -0.0524,  0.0029,  0.0368, -0.0296, -0.0072,\n",
      "        -0.0248, -0.0164, -0.0042, -0.0419, -0.0043,  0.0384,  0.0342,  0.0083, -0.0303,  0.0045,  0.0477, -0.0021, -0.0395,  0.0276, -0.0067, -0.0562, -0.0527,  0.0535,  0.0284, -0.0545,  0.0365,\n",
      "         0.0054, -0.0205, -0.0461,  0.0436, -0.0163, -0.0197, -0.0432, -0.0302, -0.0222,  0.0059, -0.0464, -0.0386, -0.0525,  0.0303, -0.0206,  0.0182, -0.0372,  0.0078, -0.0181, -0.0554, -0.0443,\n",
      "         0.0249,  0.0336,  0.0016,  0.0056, -0.0167, -0.0578, -0.0268,  0.0155,  0.0208,  0.0093, -0.0432, -0.0322,  0.0006, -0.0323, -0.0129,  0.0072,  0.0079, -0.0391,  0.0089,  0.0182,  0.0561,\n",
      "        -0.0617, -0.0271,  0.0528,  0.0295, -0.0324, -0.0592,  0.0531,  0.0547,  0.0087,  0.0179,  0.0570,  0.0004, -0.0525, -0.0622, -0.0300,  0.0574,  0.0364,  0.0533,  0.0523, -0.0341,  0.0242,\n",
      "         0.0310,  0.0392, -0.0118,  0.0274,  0.0055,  0.0012, -0.0465, -0.0445, -0.0419,  0.0090, -0.0004, -0.0141, -0.0623, -0.0345,  0.0134,  0.0235, -0.0513,  0.0426, -0.0517, -0.0585,  0.0556,\n",
      "        -0.0230,  0.0225, -0.0219, -0.0597, -0.0482,  0.0588,  0.0514, -0.0486, -0.0375, -0.0296, -0.0505, -0.0442, -0.0238, -0.0557,  0.0518, -0.0163,  0.0488, -0.0342,  0.0318,  0.0625,  0.0567,\n",
      "         0.0236, -0.0319,  0.0192, -0.0338,  0.0318, -0.0362,  0.0137,  0.0121,  0.0579, -0.0508,  0.0289,  0.0102,  0.0016,  0.0324,  0.0309, -0.0115,  0.0125,  0.0426,  0.0465,  0.0149,  0.0151,\n",
      "        -0.0112, -0.0105,  0.0196, -0.0129, -0.0561, -0.0315,  0.0029, -0.0184,  0.0347, -0.0430, -0.0066, -0.0250,  0.0588, -0.0092,  0.0539,  0.0183,  0.0545, -0.0156, -0.0349, -0.0560, -0.0233,\n",
      "        -0.0420,  0.0485, -0.0160,  0.0492,  0.0092, -0.0210,  0.0242,  0.0020,  0.0219, -0.0075, -0.0006,  0.0498, -0.0490,  0.0463,  0.0606, -0.0126,  0.0445, -0.0094, -0.0319, -0.0279,  0.0155,\n",
      "         0.0134, -0.0524, -0.0580,  0.0411, -0.0363,  0.0322,  0.0510, -0.0490, -0.0105,  0.0600,  0.0032,  0.0093,  0.0226,  0.0299, -0.0240,  0.0138,  0.0249, -0.0553, -0.0147,  0.0400, -0.0619,\n",
      "         0.0615, -0.0258,  0.0242, -0.0093,  0.0066,  0.0459, -0.0369, -0.0365, -0.0111, -0.0262,  0.0417, -0.0144, -0.0254, -0.0489, -0.0011,  0.0270, -0.0154, -0.0545,  0.0121, -0.0379,  0.0124,\n",
      "         0.0405, -0.0409, -0.0534,  0.0605], device='cuda:0')\n",
      "\n",
      "Name: mean.4.weight\n",
      "Shape: torch.Size([3, 256])\n",
      "Values: tensor([[    -0.0204,     -0.0604,     -0.0145,     -0.0126,     -0.0282,     -0.0200,     -0.0503,     -0.0611,     -0.0585,     -0.0435,     -0.0121,      0.0164,      0.0258,      0.0612,\n",
      "             -0.0475,      0.0503,      0.0517,     -0.0576,      0.0619,      0.0448,     -0.0219,      0.0365,      0.0350,      0.0204,     -0.0073,     -0.0558,      0.0294,     -0.0181,\n",
      "             -0.0364,      0.0062,      0.0419,     -0.0510,      0.0478,     -0.0028,      0.0524,      0.0621,      0.0640,      0.0493,      0.0566,      0.0062,      0.0615,     -0.0177,\n",
      "              0.0411,      0.0520,     -0.0439,     -0.0122,      0.0039,     -0.0442,      0.0342,     -0.0171,     -0.0540,      0.0243,     -0.0025,      0.0446,     -0.0005,      0.0566,\n",
      "              0.0492,      0.0394,     -0.0003,      0.0540,     -0.0217,      0.0529,      0.0587,      0.0499,     -0.0531,     -0.0436,     -0.0364,      0.0547,     -0.0149,      0.0031,\n",
      "             -0.0166,      0.0016,      0.0132,      0.0497,      0.0008,      0.0386,     -0.0399,     -0.0110,     -0.0519,      0.0086,     -0.0284,      0.0197,     -0.0533,     -0.0304,\n",
      "              0.0206,     -0.0617,     -0.0251,      0.0023,     -0.0591,      0.0308,     -0.0234,     -0.0634,      0.0455,      0.0431,     -0.0020,      0.0041,     -0.0361,      0.0190,\n",
      "             -0.0588,     -0.0233,     -0.0634,     -0.0242,     -0.0357,      0.0227,     -0.0561,      0.0249,      0.0059,      0.0524,      0.0428,      0.0599,      0.0574,     -0.0110,\n",
      "             -0.0569,      0.0214,     -0.0480,      0.0277,     -0.0407,      0.0493,     -0.0089,     -0.0070,      0.0036,      0.0296,      0.0466,      0.0029,      0.0288,     -0.0330,\n",
      "              0.0321,     -0.0050,      0.0452,      0.0408,     -0.0408,     -0.0523,      0.0568,      0.0065,      0.0212,     -0.0174,     -0.0473,     -0.0395,      0.0497,      0.0073,\n",
      "             -0.0132,     -0.0109,      0.0511,     -0.0598,      0.0154,     -0.0452,      0.0384,     -0.0317,     -0.0302,     -0.0237,     -0.0151,     -0.0432,      0.0025,     -0.0608,\n",
      "              0.0495,     -0.0165,     -0.0494,      0.0018,      0.0138,      0.0238,      0.0268,     -0.0203,     -0.0299,      0.0307,     -0.0125,     -0.0244,      0.0211,      0.0156,\n",
      "              0.0458,      0.0410,      0.0498,      0.0210,     -0.0020,     -0.0157,     -0.0351,      0.0405,      0.0395,     -0.0174,     -0.0096,      0.0232,     -0.0466,      0.0119,\n",
      "             -0.0596,      0.0052,     -0.0062,     -0.0285,      0.0626,     -0.0048,      0.0211,     -0.0022,      0.0061,     -0.0250,      0.0234,      0.0579,      0.0286,     -0.0220,\n",
      "             -0.0281,     -0.0160,      0.0433,      0.0588,     -0.0258,     -0.0625,      0.0058,     -0.0001,     -0.0025,     -0.0553,     -0.0144,     -0.0065,      0.0596,     -0.0003,\n",
      "              0.0428,     -0.0563,      0.0306,      0.0591,     -0.0468,     -0.0427,     -0.0097,      0.0407,     -0.0131,      0.0564,      0.0526,      0.0409,      0.0164,     -0.0062,\n",
      "             -0.0600,     -0.0072,      0.0436,     -0.0590,      0.0409,     -0.0459,      0.0466,     -0.0309,     -0.0302,      0.0511,      0.0244,     -0.0274,     -0.0240,     -0.0479,\n",
      "              0.0232,      0.0029,     -0.0076,     -0.0633,     -0.0029,     -0.0003,     -0.0232,      0.0138,      0.0031,      0.0520,      0.0045,      0.0079,     -0.0092,     -0.0176,\n",
      "             -0.0536,     -0.0571,      0.0070,      0.0142],\n",
      "        [     0.0134,     -0.0469,      0.0274,     -0.0019,      0.0200,     -0.0576,     -0.0545,     -0.0298,      0.0309,     -0.0276,      0.0396,     -0.0531,     -0.0090,     -0.0415,\n",
      "              0.0335,     -0.0244,     -0.0380,     -0.0053,      0.0171,      0.0229,     -0.0449,      0.0171,      0.0065,     -0.0572,     -0.0293,     -0.0472,      0.0266,     -0.0395,\n",
      "             -0.0167,      0.0216,     -0.0490,      0.0319,     -0.0237,      0.0183,      0.0573,     -0.0126,     -0.0524,      0.0449,     -0.0259,      0.0314,      0.0063,      0.0521,\n",
      "              0.0160,      0.0309,     -0.0447,     -0.0310,     -0.0347,      0.0297,     -0.0595,     -0.0164,     -0.0033,     -0.0455,      0.0119,      0.0235,     -0.0188,      0.0008,\n",
      "              0.0084,      0.0391,     -0.0129,     -0.0341,      0.0421,      0.0235,     -0.0319,     -0.0490,      0.0481,      0.0051,     -0.0050,      0.0525,     -0.0271,     -0.0148,\n",
      "              0.0099,     -0.0121,      0.0220,      0.0340,      0.0414,      0.0362,     -0.0047,      0.0039,     -0.0188,      0.0597,      0.0292,     -0.0170,     -0.0375,     -0.0267,\n",
      "             -0.0349,      0.0621,     -0.0251,     -0.0355,      0.0394,      0.0493,     -0.0304,      0.0030,      0.0543,      0.0058,     -0.0017,     -0.0014,      0.0429,     -0.0589,\n",
      "             -0.0534,     -0.0619,      0.0552,     -0.0262,      0.0491,      0.0026,     -0.0495,      0.0549,     -0.0448,      0.0543,      0.0065,      0.0012,     -0.0059,      0.0182,\n",
      "             -0.0291,     -0.0072,     -0.0399,      0.0399,     -0.0605,      0.0511,      0.0026,      0.0525,      0.0176,     -0.0145,      0.0001,      0.0625,     -0.0447,     -0.0412,\n",
      "              0.0488,      0.0406,      0.0297,      0.0449,      0.0397,     -0.0106,      0.0042,      0.0000,      0.0413,      0.0089,      0.0529,      0.0389,      0.0213,      0.0519,\n",
      "              0.0147,     -0.0394,      0.0135,     -0.0080,     -0.0089,     -0.0395,      0.0550,      0.0383,     -0.0161,     -0.0084,     -0.0468,     -0.0161,     -0.0194,      0.0302,\n",
      "             -0.0121,     -0.0098,      0.0414,     -0.0158,      0.0418,     -0.0575,     -0.0188,     -0.0461,      0.0554,      0.0300,      0.0625,     -0.0295,      0.0445,      0.0371,\n",
      "              0.0310,      0.0397,      0.0485,      0.0583,      0.0313,      0.0023,      0.0506,     -0.0090,     -0.0218,      0.0094,      0.0591,      0.0065,     -0.0067,     -0.0614,\n",
      "             -0.0273,     -0.0044,     -0.0418,     -0.0209,      0.0340,     -0.0443,      0.0172,      0.0128,     -0.0066,      0.0126,      0.0260,     -0.0274,      0.0491,      0.0401,\n",
      "              0.0190,     -0.0085,      0.0447,      0.0211,      0.0235,     -0.0006,     -0.0051,     -0.0358,     -0.0542,      0.0392,     -0.0288,     -0.0369,     -0.0421,      0.0407,\n",
      "              0.0106,      0.0495,      0.0563,      0.0578,     -0.0004,     -0.0101,     -0.0106,     -0.0207,      0.0094,     -0.0439,     -0.0055,     -0.0344,      0.0446,     -0.0237,\n",
      "             -0.0518,      0.0455,     -0.0250,      0.0447,     -0.0016,      0.0255,     -0.0158,      0.0617,     -0.0316,      0.0447,     -0.0026,      0.0175,      0.0448,     -0.0589,\n",
      "             -0.0486,     -0.0477,      0.0265,      0.0316,      0.0328,     -0.0249,      0.0272,     -0.0461,      0.0466,      0.0007,      0.0557,     -0.0371,     -0.0023,     -0.0185,\n",
      "             -0.0432,     -0.0055,      0.0539,      0.0332],\n",
      "        [    -0.0295,      0.0047,      0.0036,     -0.0083,     -0.0474,     -0.0340,     -0.0196,      0.0562,      0.0344,      0.0218,     -0.0490,      0.0016,     -0.0402,     -0.0580,\n",
      "              0.0008,      0.0452,      0.0401,      0.0615,     -0.0449,      0.0034,     -0.0217,     -0.0328,      0.0471,     -0.0467,      0.0190,     -0.0371,     -0.0287,     -0.0270,\n",
      "             -0.0294,      0.0440,      0.0413,      0.0313,     -0.0160,      0.0192,      0.0116,      0.0076,      0.0374,      0.0263,     -0.0251,      0.0041,     -0.0059,     -0.0617,\n",
      "              0.0021,      0.0359,      0.0080,     -0.0267,      0.0095,      0.0342,     -0.0288,      0.0401,     -0.0628,      0.0352,      0.0410,      0.0242,      0.0423,      0.0563,\n",
      "             -0.0290,     -0.0572,     -0.0513,     -0.0550,      0.0236,      0.0310,      0.0538,     -0.0125,     -0.0337,     -0.0322,      0.0182,      0.0375,      0.0551,     -0.0380,\n",
      "             -0.0223,     -0.0106,      0.0113,      0.0365,      0.0392,     -0.0600,     -0.0453,      0.0143,     -0.0196,      0.0330,      0.0356,     -0.0228,     -0.0081,     -0.0431,\n",
      "              0.0578,      0.0365,     -0.0429,     -0.0186,     -0.0128,     -0.0472,      0.0126,     -0.0007,     -0.0039,     -0.0555,     -0.0069,      0.0363,     -0.0002,     -0.0030,\n",
      "              0.0062,     -0.0295,     -0.0193,      0.0405,      0.0023,     -0.0108,     -0.0475,      0.0338,      0.0184,      0.0598,     -0.0620,      0.0570,      0.0067,      0.0061,\n",
      "              0.0586,     -0.0088,      0.0567,      0.0633,      0.0598,      0.0081,     -0.0092,      0.0391,     -0.0449,      0.0255,     -0.0519,      0.0569,     -0.0358,     -0.0539,\n",
      "              0.0344,      0.0553,      0.0336,      0.0049,     -0.0348,     -0.0368,      0.0362,      0.0581,     -0.0250,      0.0259,     -0.0615,     -0.0314,      0.0496,     -0.0604,\n",
      "              0.0489,      0.0553,     -0.0247,      0.0304,      0.0148,     -0.0183,     -0.0600,      0.0182,     -0.0128,     -0.0233,      0.0321,     -0.0337,     -0.0583,     -0.0614,\n",
      "             -0.0200,      0.0140,     -0.0031,     -0.0187,      0.0205,     -0.0308,      0.0069,      0.0299,      0.0603,     -0.0323,     -0.0018,     -0.0186,      0.0136,      0.0512,\n",
      "             -0.0521,     -0.0007,      0.0306,     -0.0072,     -0.0240,     -0.0540,      0.0062,     -0.0343,     -0.0568,     -0.0120,      0.0289,     -0.0209,      0.0539,     -0.0474,\n",
      "             -0.0480,      0.0271,     -0.0410,     -0.0264,      0.0384,     -0.0443,      0.0163,     -0.0227,      0.0399,     -0.0054,     -0.0059,     -0.0278,      0.0106,     -0.0588,\n",
      "              0.0286,     -0.0108,     -0.0340,      0.0248,      0.0101,      0.0549,      0.0389,     -0.0428,      0.0359,      0.0221,     -0.0489,      0.0578,     -0.0406,      0.0390,\n",
      "             -0.0090,      0.0317,     -0.0125,     -0.0388,     -0.0583,     -0.0191,     -0.0475,     -0.0501,     -0.0121,     -0.0130,     -0.0049,     -0.0232,     -0.0459,      0.0527,\n",
      "             -0.0478,      0.0362,      0.0576,     -0.0578,      0.0566,     -0.0011,     -0.0359,     -0.0058,      0.0227,     -0.0407,     -0.0073,      0.0363,     -0.0084,     -0.0277,\n",
      "             -0.0445,     -0.0185,     -0.0214,      0.0314,     -0.0386,     -0.0133,     -0.0112,     -0.0557,      0.0320,     -0.0154,      0.0254,      0.0404,      0.0188,      0.0097,\n",
      "             -0.0042,     -0.0530,     -0.0491,      0.0497]], device='cuda:0')\n",
      "\n",
      "Name: mean.4.bias\n",
      "Shape: torch.Size([3])\n",
      "Values: tensor([-0.0218,  0.0276,  0.0579], device='cuda:0')\n",
      "\n",
      "Name: logStd.0.weight\n",
      "Shape: torch.Size([256, 768])\n",
      "Values: tensor([[     0.0163,      0.0181,      0.0130,  ...,      0.0000,      0.0104,      0.0102],\n",
      "        [    -0.0332,     -0.0006,     -0.0354,  ...,     -0.0142,     -0.0104,      0.0070],\n",
      "        [    -0.0333,     -0.0222,      0.0008,  ...,     -0.0116,     -0.0019,     -0.0361],\n",
      "        ...,\n",
      "        [    -0.0343,      0.0116,     -0.0273,  ...,      0.0310,     -0.0100,      0.0253],\n",
      "        [    -0.0050,     -0.0317,      0.0022,  ...,     -0.0103,     -0.0279,     -0.0177],\n",
      "        [    -0.0223,     -0.0223,      0.0064,  ...,     -0.0139,      0.0368,     -0.0281]], device='cuda:0')\n",
      "\n",
      "Name: logStd.0.bias\n",
      "Shape: torch.Size([256])\n",
      "Values: tensor([     0.0157,     -0.0315,      0.0120,      0.0076,      0.0175,      0.0027,      0.0040,      0.0291,      0.0060,      0.0215,      0.0021,     -0.0265,      0.0320,     -0.0329,\n",
      "            -0.0082,      0.0025,      0.0279,      0.0246,     -0.0080,     -0.0169,      0.0303,     -0.0086,     -0.0079,     -0.0153,     -0.0156,     -0.0216,      0.0228,     -0.0066,\n",
      "            -0.0054,      0.0227,     -0.0361,     -0.0235,      0.0003,     -0.0009,      0.0218,      0.0348,     -0.0279,     -0.0098,      0.0060,      0.0223,     -0.0038,     -0.0171,\n",
      "            -0.0238,     -0.0284,     -0.0128,     -0.0203,     -0.0303,      0.0241,     -0.0113,     -0.0341,     -0.0202,     -0.0352,      0.0136,     -0.0307,      0.0315,      0.0326,\n",
      "            -0.0112,     -0.0195,      0.0298,      0.0243,      0.0130,      0.0135,      0.0324,      0.0358,      0.0239,      0.0222,     -0.0291,     -0.0251,     -0.0010,     -0.0286,\n",
      "             0.0104,     -0.0227,      0.0243,      0.0345,      0.0061,     -0.0323,      0.0121,     -0.0151,      0.0063,      0.0157,      0.0168,     -0.0236,     -0.0143,      0.0091,\n",
      "            -0.0096,      0.0106,      0.0052,     -0.0266,     -0.0101,     -0.0019,     -0.0358,     -0.0262,      0.0112,     -0.0015,     -0.0215,     -0.0203,     -0.0116,     -0.0065,\n",
      "            -0.0207,     -0.0283,     -0.0048,      0.0224,     -0.0055,     -0.0156,     -0.0138,      0.0217,      0.0031,     -0.0351,     -0.0120,     -0.0223,     -0.0043,      0.0006,\n",
      "            -0.0185,      0.0195,      0.0191,     -0.0091,     -0.0357,     -0.0009,     -0.0099,      0.0347,      0.0220,     -0.0227,     -0.0197,      0.0300,     -0.0108,      0.0248,\n",
      "            -0.0073,     -0.0029,      0.0025,     -0.0065,     -0.0001,     -0.0318,     -0.0272,      0.0218,     -0.0269,     -0.0038,     -0.0251,      0.0164,     -0.0204,     -0.0180,\n",
      "             0.0360,     -0.0029,     -0.0203,     -0.0189,     -0.0278,      0.0104,     -0.0232,      0.0093,      0.0183,      0.0331,     -0.0191,      0.0045,      0.0247,      0.0070,\n",
      "             0.0029,      0.0231,      0.0255,     -0.0304,      0.0003,     -0.0003,     -0.0044,      0.0090,      0.0191,     -0.0229,      0.0083,      0.0122,     -0.0182,      0.0121,\n",
      "             0.0304,     -0.0091,      0.0053,     -0.0205,     -0.0012,     -0.0001,     -0.0261,      0.0215,     -0.0163,      0.0075,      0.0263,      0.0092,     -0.0294,      0.0115,\n",
      "             0.0108,      0.0313,     -0.0015,     -0.0216,      0.0309,     -0.0157,      0.0138,     -0.0260,      0.0183,     -0.0007,     -0.0299,     -0.0300,     -0.0001,      0.0292,\n",
      "            -0.0329,     -0.0181,      0.0088,     -0.0134,      0.0209,     -0.0170,      0.0347,     -0.0011,      0.0242,     -0.0153,      0.0194,     -0.0032,     -0.0242,     -0.0173,\n",
      "             0.0333,     -0.0319,     -0.0009,      0.0320,      0.0172,      0.0235,      0.0196,      0.0099,      0.0246,      0.0062,     -0.0218,      0.0141,      0.0230,      0.0024,\n",
      "             0.0200,     -0.0229,      0.0154,     -0.0353,      0.0318,      0.0101,      0.0320,     -0.0224,      0.0162,      0.0326,     -0.0279,      0.0264,     -0.0298,      0.0119,\n",
      "             0.0142,     -0.0088,     -0.0165,      0.0069,      0.0285,      0.0084,     -0.0362,     -0.0221,     -0.0217,      0.0246,      0.0151,     -0.0228,     -0.0135,      0.0183,\n",
      "            -0.0312,     -0.0198,     -0.0023,      0.0048], device='cuda:0')\n",
      "\n",
      "Name: logStd.2.weight\n",
      "Shape: torch.Size([256, 256])\n",
      "Values: tensor([[ 0.0481,  0.0201,  0.0332,  ..., -0.0579, -0.0627, -0.0395],\n",
      "        [ 0.0447,  0.0495, -0.0119,  ..., -0.0361,  0.0328,  0.0011],\n",
      "        [ 0.0179, -0.0624, -0.0586,  ..., -0.0283,  0.0207,  0.0234],\n",
      "        ...,\n",
      "        [-0.0594, -0.0582,  0.0589,  ...,  0.0279,  0.0404,  0.0008],\n",
      "        [ 0.0443, -0.0223,  0.0549,  ..., -0.0192,  0.0494, -0.0413],\n",
      "        [ 0.0108, -0.0539, -0.0430,  ..., -0.0225, -0.0285, -0.0052]], device='cuda:0')\n",
      "\n",
      "Name: logStd.2.bias\n",
      "Shape: torch.Size([256])\n",
      "Values: tensor([ 0.0523,  0.0097, -0.0200, -0.0065, -0.0193,  0.0082,  0.0319,  0.0057,  0.0516,  0.0271,  0.0609,  0.0600,  0.0558,  0.0486, -0.0559,  0.0230, -0.0166, -0.0254, -0.0632,  0.0581,  0.0490,\n",
      "         0.0617, -0.0159,  0.0264, -0.0044,  0.0380, -0.0223, -0.0618, -0.0052, -0.0271,  0.0294,  0.0559,  0.0108, -0.0406, -0.0514, -0.0162, -0.0530, -0.0510, -0.0360, -0.0494, -0.0196,  0.0096,\n",
      "         0.0175,  0.0192,  0.0306, -0.0075,  0.0305,  0.0030, -0.0482, -0.0536,  0.0254, -0.0503, -0.0325, -0.0245,  0.0042, -0.0140,  0.0357, -0.0540,  0.0039, -0.0556, -0.0193,  0.0524, -0.0459,\n",
      "         0.0433, -0.0455, -0.0014,  0.0113,  0.0515,  0.0136,  0.0514, -0.0471, -0.0278,  0.0299,  0.0466,  0.0568,  0.0240, -0.0456,  0.0345, -0.0214, -0.0104, -0.0387, -0.0475, -0.0374, -0.0316,\n",
      "         0.0604, -0.0456,  0.0278, -0.0508, -0.0464,  0.0158,  0.0165,  0.0537, -0.0003,  0.0468, -0.0166,  0.0165,  0.0379,  0.0035,  0.0218,  0.0378,  0.0054,  0.0553, -0.0166, -0.0189, -0.0206,\n",
      "        -0.0540, -0.0330,  0.0161,  0.0518, -0.0474,  0.0586, -0.0053,  0.0321,  0.0609, -0.0239,  0.0086,  0.0457, -0.0520, -0.0224,  0.0103,  0.0066,  0.0420,  0.0483,  0.0056, -0.0150,  0.0508,\n",
      "         0.0338, -0.0100, -0.0079, -0.0509, -0.0461, -0.0337,  0.0110, -0.0354,  0.0521, -0.0022, -0.0051, -0.0551, -0.0317, -0.0406, -0.0312,  0.0149, -0.0397, -0.0447,  0.0494, -0.0333,  0.0356,\n",
      "        -0.0232,  0.0005,  0.0435, -0.0183,  0.0196, -0.0604, -0.0018,  0.0243, -0.0398, -0.0072,  0.0036,  0.0369,  0.0559,  0.0368, -0.0581,  0.0458,  0.0616, -0.0490,  0.0025, -0.0074,  0.0357,\n",
      "        -0.0084, -0.0095,  0.0559, -0.0049, -0.0181,  0.0449,  0.0416, -0.0217, -0.0173, -0.0133, -0.0551, -0.0121,  0.0066, -0.0330,  0.0579, -0.0543,  0.0313, -0.0400,  0.0442, -0.0078,  0.0418,\n",
      "        -0.0548, -0.0539,  0.0599,  0.0160,  0.0083,  0.0603, -0.0024, -0.0052, -0.0561,  0.0143,  0.0023, -0.0088,  0.0564, -0.0377,  0.0079, -0.0028, -0.0047,  0.0247, -0.0325, -0.0078, -0.0374,\n",
      "        -0.0508,  0.0332, -0.0163, -0.0021,  0.0399,  0.0413,  0.0001,  0.0421, -0.0271, -0.0606,  0.0582,  0.0174,  0.0415,  0.0568,  0.0411,  0.0432,  0.0451,  0.0251,  0.0069, -0.0021, -0.0388,\n",
      "         0.0523,  0.0251, -0.0272,  0.0580, -0.0482,  0.0317, -0.0153, -0.0552,  0.0378,  0.0120, -0.0398, -0.0257, -0.0024, -0.0247, -0.0503,  0.0053, -0.0205, -0.0232,  0.0251,  0.0540, -0.0232,\n",
      "         0.0583,  0.0340,  0.0056,  0.0047], device='cuda:0')\n",
      "\n",
      "Name: logStd.4.weight\n",
      "Shape: torch.Size([3, 256])\n",
      "Values: tensor([[     0.0051,     -0.0249,     -0.0311,     -0.0404,     -0.0503,      0.0204,     -0.0320,      0.0300,     -0.0441,     -0.0170,      0.0117,     -0.0552,     -0.0374,     -0.0338,\n",
      "              0.0529,      0.0114,     -0.0057,      0.0266,      0.0522,      0.0012,     -0.0138,     -0.0486,     -0.0041,      0.0469,     -0.0616,      0.0594,      0.0196,     -0.0038,\n",
      "              0.0057,      0.0199,     -0.0324,      0.0449,     -0.0183,      0.0040,      0.0061,      0.0477,      0.0050,     -0.0392,      0.0504,     -0.0346,     -0.0439,      0.0531,\n",
      "             -0.0285,     -0.0641,     -0.0137,      0.0319,     -0.0400,     -0.0179,      0.0012,      0.0191,     -0.0615,     -0.0404,      0.0162,     -0.0481,      0.0244,     -0.0350,\n",
      "             -0.0222,     -0.0208,      0.0354,     -0.0070,      0.0390,      0.0014,      0.0439,     -0.0010,      0.0159,      0.0606,      0.0188,     -0.0104,     -0.0111,     -0.0441,\n",
      "             -0.0067,      0.0391,     -0.0006,      0.0276,     -0.0557,     -0.0391,     -0.0090,      0.0481,     -0.0274,      0.0184,      0.0182,     -0.0156,     -0.0363,     -0.0201,\n",
      "             -0.0332,     -0.0503,     -0.0329,     -0.0422,     -0.0122,      0.0514,     -0.0522,      0.0288,      0.0593,      0.0478,     -0.0281,      0.0484,     -0.0616,      0.0263,\n",
      "              0.0165,     -0.0399,     -0.0394,      0.0137,      0.0066,      0.0470,      0.0025,      0.0109,     -0.0170,      0.0096,      0.0562,     -0.0490,     -0.0403,      0.0007,\n",
      "             -0.0419,      0.0504,      0.0529,     -0.0002,      0.0298,      0.0479,     -0.0313,     -0.0243,      0.0459,      0.0262,      0.0243,     -0.0462,      0.0394,     -0.0353,\n",
      "              0.0491,     -0.0408,     -0.0497,      0.0002,     -0.0449,      0.0002,      0.0205,      0.0211,     -0.0144,     -0.0041,      0.0475,     -0.0324,     -0.0281,      0.0084,\n",
      "              0.0180,      0.0347,      0.0170,     -0.0373,     -0.0421,      0.0036,      0.0037,      0.0039,     -0.0404,     -0.0412,     -0.0074,     -0.0549,     -0.0310,     -0.0584,\n",
      "             -0.0070,     -0.0108,      0.0261,     -0.0584,      0.0153,      0.0025,      0.0155,      0.0098,     -0.0098,     -0.0233,      0.0257,      0.0246,      0.0413,      0.0279,\n",
      "              0.0182,      0.0141,     -0.0212,      0.0389,     -0.0599,     -0.0441,      0.0264,     -0.0112,      0.0217,      0.0443,      0.0511,     -0.0352,      0.0084,      0.0104,\n",
      "             -0.0410,      0.0210,     -0.0008,      0.0291,      0.0385,      0.0500,     -0.0170,     -0.0236,     -0.0353,     -0.0624,      0.0562,      0.0218,     -0.0101,      0.0094,\n",
      "              0.0476,     -0.0341,      0.0035,      0.0528,      0.0228,     -0.0328,      0.0500,      0.0186,     -0.0046,      0.0191,      0.0441,      0.0073,      0.0593,      0.0449,\n",
      "             -0.0230,      0.0407,     -0.0022,      0.0384,      0.0216,      0.0602,     -0.0495,     -0.0043,     -0.0250,     -0.0058,      0.0338,      0.0390,     -0.0016,      0.0295,\n",
      "              0.0038,      0.0108,     -0.0610,     -0.0061,      0.0627,      0.0408,     -0.0406,      0.0088,      0.0138,      0.0364,     -0.0447,     -0.0599,      0.0034,     -0.0478,\n",
      "             -0.0062,     -0.0204,     -0.0059,     -0.0313,      0.0534,      0.0509,      0.0584,      0.0460,      0.0501,      0.0395,      0.0258,      0.0316,      0.0603,      0.0136,\n",
      "             -0.0509,      0.0130,      0.0437,     -0.0464],\n",
      "        [    -0.0252,     -0.0546,     -0.0587,     -0.0308,     -0.0136,      0.0558,      0.0183,      0.0095,     -0.0328,     -0.0178,     -0.0239,      0.0361,      0.0008,     -0.0354,\n",
      "             -0.0243,     -0.0578,      0.0416,      0.0563,      0.0328,     -0.0527,     -0.0352,      0.0379,     -0.0150,      0.0381,     -0.0060,     -0.0008,      0.0168,      0.0564,\n",
      "             -0.0424,     -0.0073,      0.0458,     -0.0286,      0.0161,      0.0222,      0.0122,      0.0348,     -0.0017,      0.0123,     -0.0525,      0.0453,      0.0295,      0.0046,\n",
      "             -0.0443,      0.0023,     -0.0496,     -0.0510,      0.0061,     -0.0070,     -0.0103,     -0.0164,      0.0167,     -0.0481,     -0.0131,     -0.0085,     -0.0169,     -0.0360,\n",
      "              0.0267,      0.0510,     -0.0445,     -0.0158,      0.0379,     -0.0179,      0.0108,      0.0146,     -0.0414,      0.0416,     -0.0490,      0.0362,      0.0481,     -0.0486,\n",
      "              0.0024,      0.0429,      0.0089,     -0.0128,     -0.0544,     -0.0254,     -0.0539,      0.0333,      0.0298,     -0.0391,     -0.0534,      0.0126,      0.0525,     -0.0117,\n",
      "              0.0491,     -0.0449,      0.0178,     -0.0157,      0.0231,      0.0300,      0.0266,      0.0272,     -0.0527,     -0.0262,      0.0495,     -0.0492,      0.0144,      0.0112,\n",
      "             -0.0621,      0.0260,     -0.0101,     -0.0090,      0.0102,     -0.0501,     -0.0201,     -0.0266,     -0.0416,      0.0349,      0.0469,      0.0473,      0.0009,     -0.0358,\n",
      "              0.0217,     -0.0348,      0.0414,     -0.0017,      0.0282,     -0.0570,     -0.0503,     -0.0155,      0.0381,      0.0324,      0.0570,     -0.0531,      0.0552,      0.0156,\n",
      "             -0.0016,     -0.0281,      0.0348,     -0.0275,      0.0188,     -0.0375,      0.0296,     -0.0114,      0.0527,     -0.0010,     -0.0352,      0.0630,      0.0472,     -0.0258,\n",
      "             -0.0589,     -0.0134,     -0.0324,      0.0256,     -0.0354,     -0.0564,      0.0260,      0.0091,     -0.0293,     -0.0016,     -0.0389,      0.0316,      0.0427,      0.0283,\n",
      "              0.0304,     -0.0407,      0.0254,      0.0515,      0.0601,      0.0133,      0.0219,      0.0150,      0.0270,      0.0622,     -0.0159,      0.0005,      0.0033,     -0.0090,\n",
      "             -0.0390,      0.0395,     -0.0297,     -0.0231,      0.0445,     -0.0597,     -0.0228,      0.0340,      0.0466,      0.0531,      0.0307,      0.0040,     -0.0279,     -0.0475,\n",
      "             -0.0196,     -0.0608,      0.0493,      0.0219,     -0.0466,     -0.0281,     -0.0193,     -0.0165,     -0.0079,     -0.0400,      0.0390,      0.0130,     -0.0098,     -0.0035,\n",
      "             -0.0219,     -0.0042,      0.0207,      0.0533,      0.0252,     -0.0529,     -0.0545,      0.0576,      0.0356,      0.0537,     -0.0442,     -0.0182,      0.0428,      0.0576,\n",
      "              0.0315,     -0.0309,     -0.0612,     -0.0187,     -0.0265,      0.0216,      0.0415,     -0.0625,      0.0051,      0.0257,      0.0618,      0.0596,      0.0226,      0.0108,\n",
      "             -0.0302,     -0.0194,      0.0448,     -0.0444,     -0.0429,     -0.0407,     -0.0313,     -0.0463,     -0.0321,      0.0177,     -0.0490,     -0.0607,     -0.0300,      0.0042,\n",
      "             -0.0233,     -0.0473,     -0.0112,     -0.0561,     -0.0291,      0.0587,     -0.0439,      0.0413,     -0.0185,      0.0159,      0.0443,      0.0372,      0.0164,      0.0269,\n",
      "             -0.0265,      0.0543,     -0.0135,     -0.0610],\n",
      "        [     0.0189,     -0.0100,     -0.0045,     -0.0279,     -0.0333,     -0.0548,     -0.0140,      0.0265,     -0.0371,     -0.0005,     -0.0525,      0.0486,     -0.0490,     -0.0139,\n",
      "              0.0441,      0.0166,     -0.0017,     -0.0367,     -0.0309,      0.0394,      0.0218,     -0.0563,     -0.0537,     -0.0278,     -0.0579,     -0.0025,      0.0225,      0.0517,\n",
      "              0.0058,     -0.0423,     -0.0354,      0.0173,     -0.0451,      0.0337,      0.0627,      0.0227,     -0.0525,     -0.0385,     -0.0539,     -0.0517,      0.0592,     -0.0141,\n",
      "              0.0398,     -0.0148,      0.0475,     -0.0226,      0.0412,     -0.0180,     -0.0557,     -0.0616,     -0.0149,     -0.0275,     -0.0348,      0.0611,      0.0572,     -0.0514,\n",
      "             -0.0176,     -0.0245,      0.0565,     -0.0169,      0.0285,      0.0454,     -0.0396,     -0.0359,     -0.0586,     -0.0599,      0.0188,     -0.0212,     -0.0301,     -0.0357,\n",
      "             -0.0139,      0.0416,     -0.0338,     -0.0027,     -0.0595,     -0.0350,     -0.0010,      0.0333,      0.0540,     -0.0362,     -0.0394,     -0.0620,      0.0538,     -0.0399,\n",
      "             -0.0591,     -0.0000,      0.0197,      0.0353,     -0.0311,     -0.0551,      0.0017,      0.0273,      0.0447,     -0.0154,     -0.0334,      0.0447,      0.0329,     -0.0353,\n",
      "              0.0532,      0.0500,      0.0518,     -0.0115,     -0.0335,      0.0591,      0.0551,      0.0551,     -0.0153,     -0.0386,      0.0033,     -0.0157,     -0.0603,      0.0011,\n",
      "             -0.0477,     -0.0081,     -0.0246,      0.0334,     -0.0201,      0.0323,     -0.0135,     -0.0302,      0.0297,     -0.0426,      0.0014,     -0.0378,     -0.0148,      0.0308,\n",
      "             -0.0343,     -0.0505,      0.0184,      0.0164,     -0.0373,      0.0617,      0.0051,     -0.0468,      0.0612,     -0.0140,      0.0361,      0.0362,     -0.0238,     -0.0229,\n",
      "              0.0589,      0.0243,     -0.0612,      0.0359,     -0.0247,     -0.0229,      0.0117,     -0.0088,      0.0118,      0.0054,      0.0519,      0.0373,     -0.0174,     -0.0331,\n",
      "              0.0483,     -0.0629,     -0.0370,     -0.0035,     -0.0346,     -0.0320,     -0.0270,      0.0299,      0.0183,     -0.0538,     -0.0501,     -0.0412,      0.0549,     -0.0494,\n",
      "             -0.0353,      0.0620,     -0.0506,      0.0333,      0.0095,     -0.0260,      0.0475,      0.0079,      0.0335,      0.0146,      0.0387,      0.0023,      0.0463,     -0.0426,\n",
      "             -0.0061,      0.0341,     -0.0490,     -0.0404,     -0.0485,     -0.0369,     -0.0408,     -0.0521,      0.0490,     -0.0331,      0.0344,      0.0416,     -0.0573,     -0.0066,\n",
      "             -0.0562,      0.0519,     -0.0088,     -0.0375,     -0.0410,      0.0267,      0.0604,      0.0571,      0.0028,      0.0078,      0.0455,     -0.0074,     -0.0062,      0.0046,\n",
      "             -0.0262,      0.0098,      0.0584,      0.0489,     -0.0293,      0.0394,     -0.0539,      0.0529,     -0.0303,      0.0462,     -0.0139,      0.0090,      0.0051,     -0.0621,\n",
      "             -0.0078,     -0.0164,      0.0585,      0.0181,     -0.0083,     -0.0319,     -0.0336,     -0.0425,     -0.0086,     -0.0203,      0.0024,     -0.0213,      0.0384,     -0.0369,\n",
      "             -0.0293,     -0.0417,     -0.0028,     -0.0514,      0.0472,     -0.0121,     -0.0124,      0.0096,     -0.0497,     -0.0355,     -0.0386,      0.0451,      0.0118,      0.0018,\n",
      "              0.0335,     -0.0579,      0.0348,     -0.0187]], device='cuda:0')\n",
      "\n",
      "Name: logStd.4.bias\n",
      "Shape: torch.Size([3])\n",
      "Values: tensor([0.0200, 0.0254, 0.0400], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in dreamer.actor.named_parameters():\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Shape: {param.shape}\")\n",
    "    print(f\"Values: {param.data}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAALPCAYAAACdci23AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAu7UlEQVR4nO3cXa9e6Vkf8Puxx/beft3b43nLBDKTNNDAQGgc0oNKFQFCkVoQRT3vp0A94Bv0A6AcVEKqOOGgEhwUiUogWlWUzjBtM+SlBBJSMok9tsez7bHHnhf76UFUqbTc/+uatbxn7OH3O7287rWee631+L+fg//m4sWL2wEAAJSOfNgXAAAAjwrhGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKDpse4/fPnllw/zOgAA4EN18eLF8t/45RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCg6bEP+wIAePCOnz4+nZ16+tR0duaZM/PZx+azMca4+d2b09l3//i78ViAR4VfngEAoEl4BgCAJuEZAACahGcAAGgSngEAoEl4BgCAJlV1wN8ZR47n3wtSFdvSCreq3m3psaefOR3XPXH2xHS2ObKJxy71zX//zelMVR3wUeGXZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAmPc/AOHr86HR28omT09lhdRinTuUxxjj9sXnHcVr35IX5Z3kopTrm+S37ge3Cc54Kszv50N293YUnBXh0+OUZAACahGcAAGgSngEAoEl4BgCAJuEZAACahGcAAGhSVQfBkcfmf1/uXpjXcqWqtVX1bmHdVN9WrZsq3NIefGhShVtS1belmrZ7YfZOmJ0vznk3zN4OsyeKdW+G2bthlh6j9/Ipd/Z38j8A+Ah4CP9XBACAh5PwDAAATcIzAAA0Cc8AANAkPAMAQJPwDAAATarqeOAOo8KtrHdbWOF29tmzcd2TT8wr3I4ePxqPfaQcC7P0J3aqUhtjjHTb0ro3inWfDLNUp/Z6sW56HNJnTbPjxTlTbdz9hceNkav10h6lvS/u9+7e/N0H+KjwyzMAADQJzwAA0CQ8AwBAk/AMAABNwjMAADQJzwAA0CQ8AwBAk57nB2hzZDOdnTh3YjpLHcVj5J7ipb3J5bHPLl/3yLFH6G+y6lLTG5K6clNvclWFezPM5o/CGKeKdS+HWbqlqac4rVkdm/a26nlOHcbb4tjk1iGc82pxztTlnM5ZrbvU7eWHntibf88BfFQ8QikHAAA+XMIzAAA0Cc8AANAkPAMAQJPwDAAATcIzAAA0fehVdSfOzquNTj8dKtqKurRY7xaOrWrjUoXb6afm5zx2KnWXfUjmzXpjHA2zNVVgJ8PsbphVf+bthdlBmKXPWa17LcxSRVvagzFyXdqavU97+HaYpSq1ypsrjk3S3q9xGNdb7V96D5OqmjA9K2+F2ZNhlt7RMcax0NGYKizvv7vmIQP4YPnlGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABoalfV/fy//vnp7OyzZ+Oxp5+ZV7gdPxU6vZZWOB2mdE2pGmpn4XFj5Bqx82H2TrHunTBLdVVVnVeqs0pNgGkf3i3OmSrn0uy9Yt209+l6095W57wXZqnGLs3GyNd7uzh2qXTf0rtUvfup+THNqs+ZvsrSuq+HWXpHK1fD7LCq6tJPKivKTXf3d6ez21cO6wEEePD88gwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANLWLh5774nPzYVW1ls6S6p9S3VdV05TWPQizJ4p1k1QrtRdmVQ1bqks7EWbVfUl1Vaku7X6xbqpiS3VqqVqv2qPLYZb2odqjVEG2VNrbSvpzN7Q+jjHy/qb3Jb1rB8U55+1kuRbuSrHuyYWz9J0yRt7f9K6lar2qMjJVKSZVZeRSae+r9yXYOT/v61RVBzxK/PIMAABNwjMAADQJzwAA0CQ8AwBAk/AMAABNwjMAADQJzwAA0NTueR5PhVnVyXo6zFIn690wm1eG/kDqrU2qDuPU55qkTuXUi1xJPcRVn3D6rK8tuJaOmwuPq/Y9deWmbtrqfqdnN/X3pr1/vDhn2qO07n6x7hthlvY39RtX3yBpf9c89+m7Ie1R1VOcupOX9irfWHhcpeqsXir9pFJ1UodO+t29VPoN8OjwyzMAADQJzwAA0CQ8AwBAk/AMAABNwjMAADQJzwAA0NSvqksxu6oRS5VeSy2tjapcL+ZV1dXM0oq2yrthVtVKJalCsLrft8PsQpil6rKq7uuJMEvXUz1HqaourZtm1Z+saX9TDVuqb6uOTbP0TqTnb4xYXRbrGyvpWan2IUnvd3qfUiVfqvobI9dupu+N9GyOMcapMEtVlGfD7Hhxzsvz0c5+1S8K8GjwyzMAADQJzwAA0CQ8AwBAk/AMAABNwjMAADQJzwAA0NSvqrsUZlV9W6qkWlpXVVVkpbqvNKt2JNVOpXqyVBtVNThdC7PzYXasWDfUSpU1WMnSmra099UzlirRUg1btW6qyEsVjOmc6V0aY3kdYlWzuFSqYatqC9P9Ts/9mvc7Va1V1YSpjm4vzNI7WtW7pe+G9C6t2ft0bHqu07NQUFUHfFT45RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgqd/znLpKq07WdJbUJ3wrzKru1NT1ejXMqirSM2F2J8xSf2z1WdKfOO8Vxy6V9n5pD/EYY7weZis6ZOO6ayzt2U17lLrCK6mDd684Nr2nd8PsyTCrepPTunthdrNYN32W9D5V33jpfaq+52ZSB/kY+blPs2rv0zw9n+ndX2FnT88z8NHgl2cAAGgSngEAoEl4BgCAJuEZAACahGcAAGgSngEAoKlfVfd4mL1RHJtqkVJ7Uap+q2rN0jnTnwypCmyMXF229LhqzfRZbyy4lo63DmndJFWMVXVfp8LsWJgdFOum5z5V1V0Ls/3inKkuLVXyrWkCS/c7PX9VbeG9MEvPfXW/07qpirKqdkyfJ627RvWdM5OevzHy+5T2IdVqnizOGWruVNUBHxV+eQYAgCbhGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmvpVdXfDrKqrejfMri88LlVVjXF4VWtVhdZMqpWq/oRJx6Y7WDVDpaqwVEl1ulj3SpidWXjOS8U502dNlV0HxbqHIVUwjpGf7fSupXepWjfV0V0u1l3qsGoW0/uUatjGyPuQ6hDXfFedD7NQ/VbW7i2tF03fN1VVXfh/Yvf8bnEwwKPBL88AANAkPAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQJPwDAAATf2e56pDdqnUq5pUsT/1/qZO1sq5MHszzFK/7F5xzrT3ad3UqTxG7qxe00udrint/dLrGSP34a6R9r7qN585rH7jd4r50j+VUz1vtWbqEk/9xtX3QtrDJ8Os6thO66b3KX3ONBsjvy9pf6s9St38Szu/Uz/0GPEZPHm+KokGeDT45RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaOpX1e2HWVX9lqqanll4XFX/tBdmqdasqrI6HmZpN9MevVecM1WipXqym8W6qa4q7e9bxbqp6irtQ3VPk1Rzt0aqETsWZqkmrGrsStVwr4dZqn4bIz+fr4XZ6TCrKgTTPU37l57NMZa/E2vetfQ+pXNWn+VymC2t8hzjcOpFq88SnNg78eCuA+BD5JdnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKCpX1WXWoaqCJ7qqlL1UaqNqiqc0jnXVFldDbP0WdL1XinOuVRVIZike5rq2yrp2FThluoFx8jP59kwu1asm2rjUoVbqn5LFW1j5DrEVA1X1Yj13/a/KVUTpne0kmr3VlSilfd0qfQMpvtS7VF6HtK6VT3jXpil74ZUs/hkcc7wvbu7n14mgEeHX54BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKBJeAYAgKZ+edUbYVbVxqWqplTptcaNQ1o3fdZUK5X+TDlVnDPVSqVqvfPFuqnOL637eLFu2vtUQZaq6lJ91hjLK9OqPx9TrWGqcEvSvo8xxp0wS5/z4P1fSkt1vUuld6mqQ0zPZ3qOqm+8m2GWnvv07lfVeek9TZ+zqqpLzXDpetPzt8Jju/PNP3I8v4j336n+kwH44PjlGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKCp3/OcOkXXRPDjYZa6Xqsu0tSdmipDD4p1nwyz1EWc1j1TnDP1Cade2urupv1N97vql037m3qTU5d46rquzrm0N7lSdU/PpK7rMZa/T8eK+YkwS89Y6gtOncpjjPF6mJ1dse6lMNsJs7QHY+T3KXUjV73USXqOUs9zJb1Pad30Ll0uzhnep82R+QbunE03bYy3ri0tVQd48PzyDAAATcIzAAA0Cc8AANAkPAMAQJPwDAAATcIzAAA09avq9sMstwzleqNUV7Wmqq7/yd6fVJmWKp5SJdqN4pypViqtu6JWKs5S/dgaS6vfxsg1YqmerKoCS/twLsxuhVm61jFyzeL1MKvq0tK7lioE05/YVT1eOjbtfbqeyu0wq2oW071Je7+m8vBgxbFJ9VmXSNWiY+T9C+/3zr6qOuDR4ZdnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKCpX+iWatjSrJIq59ZE+4MwW3O911YcO5Oqtdao9i9Vm6VKvlTRNkauIEv3+6kwq/YoNVmlmsVUKTdGvt5UgZdq99LejjHGvTBLVWBVvdubYZbeibT3VWVk+ixp76v7kqSKtjX1bel9Sd+k1TlTS1uaHRTrpuc+VQy+FmZninOm75wVVXUADxO/PAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQJPwDAAATcIzAAA09Xueb4bZjRVXcFgdx6lLt/+p/3+pjjR1p6aO3ao3Oa2beqcfL9ZN3b5p3aqSNfU8L73f1Z95qU84dUBX3cjps6Q9SsdVPeOpZ3eNql96JnVLp1k1T+/hbrFuuqfHw+xsse7rYZae+9R/XN3P9H6nfai+d7fFfImq1zt1YQc7e3qegUeHX54BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKBJeAYAgKZ+aVuK2VXL0N0wSzVNqf7penHOU2F2OswuF+um6qg0uxVmVb3T0mq9qoatqkybSbWFa9ZNlV5L1xxjjIMVxyap+m1NvVt6dtM5U13fGGOcD7P0fKZzPlGcM9WppetN7+gY+ZpSRVv1c0Gap3NWFW5JOja9w1UV3RsLrqVySNWiu+erbkKAh4dfngEAoEl4BgCAJuEZAACahGcAAGgSngEAoEl4BgCApn4J2vEwO1ccmyqpUk1bqrGrYn86Z6qcqtZdWiuVpDqvMepKqpmDhcdVqlquqoptJj2N1X1JdYip8rBaN92bp8IsPQtVhdjZMEt7Xz1HaX/T7O0wW1OHmN7Dg2LddN50zkvFukl6D9PzV0nfVe+tWDfd0/R9nj5LVUt6MsxCvejunqo64NHhl2cAAGgSngEAoEl4BgCAJuEZAACahGcAAGgSngEAoKlfVZcqk26tODbVVaWKrFTvVK17uzg2WVMdNVNV0aXKvlTZdaJYN7VDHYRZVU2Y1k1VYalSrnpSU71W2oc1fz6mSrQ0q+53ep/S/a7WvRZm6X1J66Y113hrxbGpKjG9S2Pk+5akZ7f6vknP4PkwC9VvY4xcA5re4XRPq/clVeCF69nZrzrwAB4efnkGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaOr3PKce2DSrpE7W1FNaxf607skwu1Osm3YsdaemTtaqezatezXMUufqGLmP+WaYVX3CaZ7uW+r1XvOMpc9S9PputuFBejEceBBmP5LPuS03eKHUjZ7etdRtfro4Z9rf9K49Uayber1Tr/KFYt3UsZ2uN71LqZt7jOUd25W0bvqc6Tmp+rfTOxyeIz3PwKPEL88AANAkPAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQFO/qi5Vv50vjk21UqnGKdVVpfqxat1Ur5Vqmqp5+lMkzapzpv1LVVZV7V7ao1QxVu390pq7VJ+1Rqjs2lxJD/YYmz+Zz9OxR7fzD3rvq/mc939lvvnbT4QNfD0uO8bj6aRhdi3MThXnTDV36flM1Xlj5PcpfZZUpTZGvt70nh6sOGe63sthtqbGrqrPWyo92mG2u5+6/gAeLn55BgCAJuEZAACahGcAAGgSngEAoEl4BgCAJuEZAACa+lV1yYliniqeUg1bqo1K9U7VsW+GWVXhlNZNtVLV9SZpj9ZInyWp/uRKz0Oq7QpP4+Z6USn3jVAp971wbKphG2OM0KD1yZ+Zd4U99sx8k77/X47HU976d/NNuv9LocbufNFdFir7FteepXdpjPzup3NeKdZN71Nat6rzW+qtMKvel3S9OwuPGyO/3+fCLL2j6RkaY4wLYXZjPtrZSx8U4OHil2cAAGgSngEAoEl4BgCAJuEZAACahGcAAGgSngEAoEl4BgCApn7Pc+oUvVocmzpZUw9s1fW6VNVNm6S64bSbaQ+qDugzYbamA/rxMDsIs6pfdm8+2nxlvoFHfi/8LVd1Uqf78vR8tP3H+cNsPzmf/8XpcOzRcFN/Nn+YI38w34cjvzufbS/mz3L/J9eUjU+kfuMx8n1Zc1zqEk/vxNkF1/J/3Ayz8IyV3cipe/p8mFV7n77nUq3y0l7+6tjweO7uh0J1gIeMX54BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKBJeAYAgKZ+VV1SNWAtras6FWZVXVqqcXoyzN4u1k31TxfC7HaY3SrOmfYh7X31WdIepj+rinU3b4Y6uj+cL/zsuePT2asv5JNun5l/mO2p6mFZ6M7C44r3Yfvz4XpfDAe+lNc9+tdHp7P7F+cP0vbpcD3n8jnHyTB7LcyqdY+F2eUwSxV3Y+R7k6rq1lRRJul7453i2HTeVI+XqvWqz5LuaXDsdLqhY2yOzm/M9t4hvd8AE355BgCAJuEZAACahGcAAGgSngEAoEl4BgCAJuEZAACaHkxV3X4xTxH9SpidDrOqMilV1aXrqXYktSKlNrX3wqz6LAdhluqq7hXrpkqvFe1Pmz8NfV9hj77/z+cdWfd3ik1aWru3k5eN9zQ9K2fC7EY+5fZ4qN37lfls82zuwNu8GCoEf2++SdudsLmfjKcc2y+Ez/JYWLeqYaue7ZlUNzfG8lq5q2G2pkmteFYWS3V06X2p9mdhvejmrfzsnjg37xi8e/1ucVEAD5ZfngEAoEl4BgCAJuEZAACahGcAAGgSngEAoEl4BgCApn5V3dEwS7VH1bHJm2G2pv4p1eNV66b56wuupePOwuOqz7IbZqkKLNUAjjE2X5/XTm0/O7+oe6fCSZ/I54zPSqqbO1esexBmaX+PhVn1PqRaw/CubZ/LN/ze8/P93Vye37PNK2H250U9XngWxuPz0fYz+bNsP3VIFXhLf05I9/t4ceztMEt1ndW66fvoQpilrU+VfGPkisb0/0TxnbJ7fv5lpaoO+KD55RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgqd/zfD/Mbqy/kL9V0f25WOrZrf6cSJ3BqeM01eHeLM6ZOlnTfal6p/fDLFSnHvnvxSaFuubtT4cS2dRvnHqnx8jdtOnYW8W6qZs2rZu6xNd8lkOqtN2eD73JPzOfbd4uep6/HTqi/yzM/nOx7ouhS/zT4bP8ZNEf/ckwT/f0VJilPvUxcs9z6o9Os0p619ZIfevVcx/snNtZfjDAA+aXZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgqV9Vl1SVSamqKVWFnQ6zk8U5XwuzVCl3olj30sJj005XVXW5XWu5VJEVKto2X8s1YtsfDVVh98KHSbV76X6uUe19krdhbs2frKkSraqxS9ebagtDFeV2t6h++7kw/+x8tLlcVNW9GmruXgmz4tkd5+aj7Y+E5/qzYXZ/xQucns813wvXVxybpO+UFXb2VNUBDw+/PAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQJPwDAAATf2quuNhVlXVpcq5O+0r+Juq2J/m7yw85xi57ivV7q1x7ZDWDRVkm78IH7T4nNsXDqFbL1W0jZFru94KswvFuulZeTPMngyzqs5raX1jte1vh1l6X9a8S6k+L1zv9smiAu9j8/nmhfDsfjMuO458Y/5hNy+FCrz/Np9tny8+y98PNXdPh2Or78D0XZW+z9Os+o5LNaCpXvRyXnb3fOo7Bfhg+eUZAACahGcAAGgSngEAoEl4BgCAJuEZAACahGcAAGgSngEAoKnf85yqSquu19AnPO6FWerDrfpG7684dqnUaZs6V9NsjDGOhlnqZK06tEPv6pE/n/9dtf17RW/tDy3spr0SZqnfeIx8v1PPc/UGpHXTNqRO5bRmNU/vUvUevhdmqWc3fc6qW/p6MV8qfG9sj4aL+vG87P3Phc3/6/lo87XQAf3d/IJvvjWf3/+l+fVsP1ts/tUwS98bqau5+k5JH3Vpl/gYY2d/pzgxwAfHL88AANAkPAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQFO/qq6qwTqMY1PtUapaGiPXcqXqt1PFum+GWWpTSvVPqVJqjHxNaZaq88YYm3fDBr82H/3QF3Jt1P+6l7rhFkq1hWPU9W8z1d4vXff1hcdVqn1YKr1PqRHt3WLdvTBLdX7Vd8aTYXZz+brbvap7b3Lcs/Pjjp7Ja37iy/Mvq+/85Yn5OX982bWOMfJ3Q1q2eh/S92OaFevu7u8WJwb44PjlGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABo6lfVpXayVAs3xhiPh1mqL7q3cM0xxjgo5jNVI9IhtLDFSr4xllf9VU1WoY5us50ffP3oG3ndN+b1WovdevBLjjHqPUpvSKppOxlmqSpxjPxOPBFm6X0ZY4zrYbYfZun5Kx6F+D6lvS9qFmO1WXqfqj1KVYDpey7M7t3IL/h3fii8L+l6rsRll6vqB5P0c0x6l4r/Q3b2cz0mwAfJL88AANAkPAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQJPwDAAATf2e51TdW/U8p17bFN9Tv+zbxTlTn2u63qq3NnWgputNfa1V13A6553i2CR05W43827aW+eKztVj4QOlQ1OXc9W/fTrMrobZuWLddL2Xwixd77HinKnnOan6o5P0PqXnr3p2Xw+z9I6mHucxxrhczJe6cQhrVj3uS489UxxbfUfOpM7vmwvXrNZNz8kYY3ev+gIA+OD45RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaOpX1b0VZqlyaoxcK1VVUs0U1UaL3T2kdVPlWVX1l5wNs1T9Nsb7ufvv77hUa5jqtVLtXlXDlq4p/YlY7X2qH0xSNeGa6rL03Fe1cUlV0bhUqktb86d7esbS/lbv94UwS58lvWtPFec8GWbpnaiq6pKl71r1HqY9WlqdN8bY2S/qMQE+QH55BgCAJuEZAACahGcAAGgSngEAoEl4BgCAJuEZAACa+mVl7x7SWVL1UaoRO1ecM11vqquqaqXeDLNU/7QfZjeLc6bPkiq70vWMUVcMzlSVaKneLe1fWjdVJVbz9DnT9ayRnrGqqi7N05+7x4p10/OQ6tLSM1ZV3D0eZundv1Ksm97/9BxVVXXpu2pprWZVhxiez802PAzV90aqhkvvRKoWrd79NF9RL7qzp6oOeHj45RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaOpX1Z0Ps+vFsamuKtWwpWqj3eKc6c+CVGtWVTGldVOVVTpnVQOY5tdWrHu8mM9U9W6pai3V2C1dc4z38yT/TdWfj6nC7XaYpXq3s8U5r4bZqYWzMXJ1WXoW0rtWVdWl92lp9dsYuXaveoeT9F2W6t3SOavavYOF694q1l0qVQhW72Hao9NhVnxXnbgfXqil38kAC/nlGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKCp3457bMVZ7obZ0h7Oql82rZu6Uy8X6y7tkD1YeFwl9aNWnaxL/3SqnoX0VKW+8NRbm/pjx8hd4ulZqfYodSen5zo9J9U5w/zIfww3LXWJjzG2n55f1PaxcMHFulHa+zV9zFXX+FLpfUr9x8lOHh99L5Sfh+u5t198fafnLPVZPxFmqSt8jHy/U89z8Yxt7sw/zM7Z+QbfPUgvKcAyfnkGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJr6VXVXV5zlYMWxM1Vl0lLHVxybrmkvzKq6vpth9kyY3SnWXbiHH9umzqkxvpd6xNITl6rAQptXOU/7W1XgHYRZqjVL11Pcl81fhlqul+b9bjtnUq/eGDe+EU58YT66/2PzDUz1d2OMfE9ThVtVj7cbZifD7Fqx7n6Ype+GVHGZb8vYHgudcun5rL69q0rEmfS9kJ75MXL94MGKdYMTeyemM1V1wGHwyzMAADQJzwAA0CQ8AwBAk/AMAABNwjMAADQJzwAA0NSvqjsWZlWNWKqVmrcM5WqjveKcqVbqtTA7W6ybpDq/dD1VVV3yXpgVLWLbY/N/sD0xn9352vW88BfCw5L2KNVyVXtUVZAtlfY3SX+WFnWIm2/PO8aOPDe/oIN/kfvdtq/M7+mRl+YXfOQ/hQ/zSjzl2P7U/Jz3fzrc1Oo7Je1v+q6qfi5I9zsdm2rhitq9bXogUp3f9aJncen3SvF6L5b2YWmt3hhjd3/+H8yN79xYvjDAhF+eAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJr6Pc+Ph1nqTR4j966mDuhU0Vl0GMfe0DS7s2Ld5I0wqz5LcmXFscnz89GN76Xy2THGNvTPps+a/pSrOmvPhFnq7q36hC+EWeqtDc/R5rH8EG1enc9v/8LR6Wx7qtikH5uP7n8qHPv9+ejIi/nv780fzT/L0f8aPstP5Jdi+6Oho/xOOLZ6jm4W8yWK75TtvXC9J1ecN3Xovx1m6Tu56CiP3fzp/5Dqf6Lwf8zOfvF9BPCA+eUZAACahGcAAGgSngEAoEl4BgCAJuEZAACahGcAAGjqV9XdXXGWVOmVKpNSW9XBsksp3TqkdVNd2po/YVJL07wJ7Aduz0fbfzjf/M2/zVVrR741/0D3/1HoCkt7dC2ecozTYZaeseq5TnuYZuFjbv5H0XcYqh23z4aX4npedrwb1k11aU/OR/f+WaglHGNs/nr+WTdfC7OXijq/P53Pt58JNXYvFBV4+2GeKtzSd1xV75Yq5ZL0zI8xxqkwS/Wi6Xqr6ryl9aIr6jp399ONAXjw/PIMAABNwjMAADQJzwAA0CQ8AwBAk/AMAABNwjMAADT1q+qqGqwktVmlerKkuvJU/3QnzFL12xi5qumNMEu1UqlSaowxLi08tqrICvVa26dC3dfnc6/U5uV5jdjJH50/DG+dqrr1glSRlZ6/qiLr8sJjw2zzZ7mGbfvphb1dqZKvki4pNYEV7+/2k+E5+gehDjFU3I0xxpE/mf/dv/lGqMALszHG2D4frvdnw+x4uuHxlPV8JlQPjjGW14um2r01laXp+3GFnb3qSxvgwfLLMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQ1K+qOxdmVX1RqmLaD7NUbVTF/nS9qeKpWjfVv6VjU11aVTmV9u92mK2pLjuYj7Y/VlTVhSq2Z3/36ensL3/42nzRT8RTjm3ZObdQekPCfdl8NwyL2sftLyysPZtv7Q+k9zRV/e2FWXr+qnmok9w+k+/nvX8yf6E2R0JV3R/nXrjNV8Ox/2Y+235sfr3Hfjyf88lX55/l1efCsalSrjOfSd9Va6R3qarVDM/u7vnUpQjw4PnlGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKCp3/N8KsyqXtCqx3gm1aO+VxybOk7vh1nVWf1OmKVrSntwqzhnUl3vIdieyh28939uvsHf/pN5yfGRF8Pfci8W1/R4uKZPh+P2i37onwizo/NjT/3hyensztP5pm0/Ea4pVGHH53qMEauw02xNl3j6bkifpXq/w2dNnd/bzxcd5S+Enuf/GWahH/q9/xBPOb4/js7X/eHwWR4rnt30nX0nzOaXkzu/xxjj9TBLXc5ni3Wvzkc7ezvFwQAPll+eAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAICmflXdG2GW6tvGyBVal8OsaGKKqmtaKv25kar10nG7xTlTs1m6g1X9U7qnqf3pTF52+978xt37l/Puss2NUAX2StrcMcar89HmpbDuvWLdP5qPnjkzf7CvXZnftPv/tOiUu5HHU68tPK6y9HoqqcauuC1xfjrMitrMbagf3P7CfLb5Qrigr+dzjo+H67kQvgSrmsBUVZeqAKvq0SR9z6W9T9WiY8T/C3b3qy9QgAfLL88AANAkPAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQFO7qu7u9+bVWzuPp16zQjo0NXqlqqUxxtgLszsr1r0QZqnSK9U/VZVyS6ujqrt7NMzSPlQ1gKlGLNTubU+GmrDPFr2FPxUu53a4oFBxN8YYm0vzYy9dmv/tuf2p8FmeLj7L0vt9opin5+F2mJ0Ls+rP71SHmN6lag+uhVmqqqvq3dL1hv1Lz+74keKc+2GWKtyqPToIs/QOp3VTtegYy+tFq/sS7Oyv+P8HYAG/PAMAQJPwDAAATcIzAAA0Cc8AANAkPAMAQJPwDAAATcIzAAA0tXuet0+EAs/UAztG7k5NHaepjzl1Ko+RO2/XdBinDtSlvdRvFud8d+E5rxTrps+S+lrTfamkfUj90Cts98OHOVUc+xPh2JPhwIMwO5PPGa/pUpil6xkjd6qnnuf0LdH+BvlbpG7fNc9C+m5I78sY+blPHcfpuKr7+PVivtSa93SmqlRO73fa++r/kPBZdvb0PAMfLL88AwBAk/AMAABNwjMAADQJzwAA0CQ8AwBAk/AMAABN7aKpt2/Me6V2z+zmg1NVU6rIShVta+qflla/jTHGa8V8iaqqLkmVXlXd19GF5yzq3cbdMEv37XyYHRTnTH8G7oXZtWLd9Iakhqy0t9UzlubpnqbqtzFyNWFyM8yq9zA5WHFs8tYhrZvuabovVf3l2TBLz8KtYt2nwiy9o+l+p2rRMfL3ebreFRV4J87Me0k3R+c3ZntvzcML/F3ml2cAAGgSngEAoEl4BgCAJuEZAACahGcAAGgSngEAoKldVffGS29MZ3un95ZfwY3lh0apji79yVDViJ1ccC1j5PqsJ4pjUwVZqoaq1k3VUXfCrKqqS5VoqbYr3Zeqdi+dM32W6n6nSq/0jIVqrbJibGl14WFVtKXPUtUdpvt2PMzm7WM/kPYoVb+lc44xxtUwOxdmaR+qestU07amqi41saV3bWm16BjLa0BTtegY8Rk8cnz+YY6dPDadvfNm1SEI8LfzyzMAADQJzwAA0CQ8AwBAk/AMAABNwjMAADQJzwAA0NSuqvuDf/UHh3kdAADw0PPLMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQ9NiHfQEATHw8zF79wK4CgP+LX54BAKBJeAYAgCbhGQAAmoRnAABoEp4BAKBJeAYAgKYHUlV3+vTpOP/Upz41nX3lK1+Zzj7/+c9PZ1/96lfjOff396ez3d3d6ezSpUtx3RdeeGE6e+mll+KxAO/L42Gmqg7gQ+GXZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAICmB9Lz/Ou//utxfuHChensd37nd6azX/zFX5zOqj7m5557bjrb2dmZzr75zW/Gdd9+++3p7Fvf+tZ0dv369bguAAAPP788AwBAk/AMAABNwjMAADQJzwAA0CQ8AwBAk/AMAABND6Sq7sSJE3H++7//+9PZF7/4xenst3/7t6ezX/3VX43nvHXr1nR25cqV6exzn/tcXHez2Uxnv/VbvxWPBQDg0eaXZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCg6YFU1VWeffbZ6eyv/uqvprPnn39+OnvnnXfiOU+dOjWdnTlzZjr79re/Hdf9+te/Pp19/OMfn84uXboU1wUA4OHnl2cAAGgSngEAoEl4BgCAJuEZAACahGcAAGgSngEAoEl4BgCApgfS8/ybv/mbcf6lL31pOvuN3/iN6ezXfu3XprMvf/nL8Zyf+cxnprOzZ89OZ6+88kpc95d/+Zens5dffjkeC/C+fOfDvgAA/l9+eQYAgCbhGQAAmoRnAABoEp4BAKBJeAYAgCbhGQAAmjYXL17cdv6hGjYAAD7KLl68WP4bvzwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQJDwDAECT8AwAAE3CMwAANAnPAADQ9Fj3H168ePEwrwMAAB56fnkGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAIAm4RkAAJqEZwAAaBKeAQCgSXgGAICm/w3PgW/aqwiOGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1920x909 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try out rollout of the world model\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "# Initialize your Dreamer model and device here\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the start image\n",
    "start_image = np.array(Image.open(\"startImage2.png\"))  # Replace with uploaded image path\n",
    "start_image_tensor = torch.from_numpy(np.transpose(start_image, (2, 0, 1))).unsqueeze(0).to(device).float() / 255.0\n",
    "\n",
    "# Initialize the rollout\n",
    "recurrent_state, latent_state = dreamer.rolloutInitialize(start_image_tensor)\n",
    "\n",
    "# Define dark mode colors\n",
    "BG_COLOR = \"#333333\"\n",
    "FG_COLOR = \"#DDDDDD\"\n",
    "SLIDER_COLOR = \"#555555\"\n",
    "SLIDER_THUMB_COLOR = \"#AAAAAA\"\n",
    "BUTTON_COLOR = \"#444444\"\n",
    "BUTTON_HOVER_COLOR = \"#666666\"\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Dreamer Rollout Interface\")\n",
    "root.configure(bg=BG_COLOR)\n",
    "root.attributes('-fullscreen', True)  # Fullscreen mode\n",
    "root.bind(\"<Escape>\", lambda event: root.attributes(\"-fullscreen\", False))  # Exit fullscreen with ESC\n",
    "\n",
    "# Position window on primary monitor (top left corner)\n",
    "root.geometry(f\"{root.winfo_screenwidth()}x{root.winfo_screenheight()}+0+0\")\n",
    "\n",
    "# Styling configuration\n",
    "style = ttk.Style()\n",
    "style.theme_use('clam')\n",
    "style.configure(\"TFrame\", background=BG_COLOR)\n",
    "style.configure(\"TLabel\", background=BG_COLOR, foreground=FG_COLOR)\n",
    "style.configure(\"TButton\", background=BUTTON_COLOR, foreground=FG_COLOR, font=(\"Arial\", 12), relief=\"flat\", padding=8)\n",
    "style.map(\"TButton\", background=[(\"active\", BUTTON_HOVER_COLOR)])\n",
    "\n",
    "# Display for rollout images\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "fig.patch.set_facecolor(BG_COLOR)\n",
    "ax.set_facecolor(BG_COLOR)\n",
    "canvas = FigureCanvasTkAgg(fig, master=root)\n",
    "canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=True, pady=(20, 10))\n",
    "\n",
    "def update_observation_image(obs_image):\n",
    "    ax.clear()\n",
    "    ax.imshow(obs_image)\n",
    "    ax.axis('off')\n",
    "    canvas.draw()\n",
    "\n",
    "# Frame for sliders positioned to the right and centered below the image\n",
    "slider_frame = ttk.Frame(root)\n",
    "slider_frame.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "action_labels = [\"Steer\", \"Acceleration\", \"Brake\"]\n",
    "action_ranges = [(-1, 1), (0, 1), (0, 1)]\n",
    "action = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float32, device=device)\n",
    "sliders = []\n",
    "\n",
    "# Spacer to push sliders to the right\n",
    "spacer = ttk.Frame(slider_frame, width=200, style=\"TFrame\")\n",
    "spacer.pack(side=tk.LEFT)\n",
    "\n",
    "# Action sliders with custom ranges and names\n",
    "for i in range(3):\n",
    "    label = ttk.Label(slider_frame, text=action_labels[i], font=(\"Arial\", 12, \"bold\"))\n",
    "    label.pack(side=tk.LEFT, padx=(20, 10))\n",
    "\n",
    "    slider = tk.Scale(slider_frame, from_=action_ranges[i][0], to=action_ranges[i][1], resolution=0.01, orient=tk.HORIZONTAL,\n",
    "                      length=300, bg=BG_COLOR, fg=FG_COLOR, troughcolor=SLIDER_COLOR, sliderrelief=\"flat\",\n",
    "                      highlightthickness=0, activebackground=SLIDER_THUMB_COLOR)\n",
    "    slider.set(action[i].item())\n",
    "    slider.pack(side=tk.LEFT, padx=(0, 20))\n",
    "    sliders.append(slider)\n",
    "\n",
    "# Step function\n",
    "def step():\n",
    "    global recurrent_state, latent_state, action\n",
    "    action_values = [slider.get() for slider in sliders]\n",
    "    action = torch.tensor(action_values, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Rollout step\n",
    "    next_recurrent_state, next_latent_state, next_observation, next_reward = dreamer.rolloutStep(\n",
    "        recurrent_state, latent_state, action\n",
    "    )\n",
    "    recurrent_state, latent_state = next_recurrent_state, next_latent_state\n",
    "\n",
    "    # Convert observation to image and display\n",
    "    obs_image = next_observation.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    obs_image = np.clip(obs_image * 255, 0, 255).astype(np.uint8)\n",
    "    update_observation_image(obs_image)\n",
    "\n",
    "# Close (X) button in the top right corner\n",
    "close_button = ttk.Button(root, text=\"X\", command=root.destroy, style=\"TButton\")\n",
    "close_button.place(relx=0.98, rely=0.02, anchor=\"ne\")  # Position in top-right corner\n",
    "\n",
    "# Step button below sliders\n",
    "step_button = ttk.Button(root, text=\"Step\", command=step, style=\"TButton\")\n",
    "step_button.pack(side=tk.TOP, pady=20)\n",
    "\n",
    "# Initial display\n",
    "update_observation_image(start_image)\n",
    "\n",
    "# Run GUI\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original = selectedEpisodeObservations[0][1:].cpu()\n",
    "reconstructed = dreamer.reconstructObservations(selectedEpisodeObservations[0], selectedEpisodeActions[0]).cpu()\n",
    "sideBySide = F.interpolate(torch.cat([original, reconstructed], dim=-1), size=(512, 1024), mode='bilinear')\n",
    "saveVideoFrom4DTensor(sideBySide, f\"results/sideBySideRepresentation_{runName}.mp4\", fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 3, 96, 96]), torch.Size([255, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedEpisodeObservations[0].shape, selectedEpisodeActions[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
